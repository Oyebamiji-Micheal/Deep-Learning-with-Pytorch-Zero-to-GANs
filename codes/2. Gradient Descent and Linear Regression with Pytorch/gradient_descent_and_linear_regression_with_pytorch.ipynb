{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30fa49f2",
   "metadata": {},
   "source": [
    "# Gradient Descent and Linear Regression with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730b7633",
   "metadata": {},
   "source": [
    "## Introduction to Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53781c5f",
   "metadata": {},
   "source": [
    "Suppose the temperature, rainfall and humidity was recorded along with the yield of apples and oranges in five regions as shown below\n",
    "\n",
    "<br />\n",
    "\n",
    "| Region | Temp. (F) | Rainfall (mm) | Humidity (%) | Apples (ton) | Oranges (ton) |\n",
    "|:------:|:---------:|:-------------:|:------------:|:------------:|:-------------:|\n",
    "| Kanto | 73 | 67 | 43 | 56 | 70 |\n",
    "| Johto | 91 | 88 | 64 | 81 | 101 |\n",
    "| Hoenn | 87 | 134 | 58 | 119 | 133 |\n",
    "| Sinnoh | 102 | 43 | 37 | 22 | 37 |\n",
    "| Unova | 69 | 96 | 70 | 103 | 109 |\n",
    "\n",
    "<br />\n",
    "\n",
    "Using the average temperature, rainfall and humidity, we'll create a linear regression model which predicts the crop yields for apples and oranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991b6d07",
   "metadata": {},
   "source": [
    "The yield of apple and oranges can be estimated as a weighted sum of the input variables   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18297534",
   "metadata": {},
   "source": [
    "> apple_yield = $w_11 * temp + w_12 * rainfall + w_13 * humidity + b1$  \n",
    "> orange_yield = $w_21 * temp + w_22 * rainfall + w_23 * humidity + b2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70a18156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fb364a",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbc5f5e",
   "metadata": {},
   "source": [
    "We can represent the inputs as a 2d-array with each column representing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "93c994df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4d83e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets (apple, orange)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe332ba5",
   "metadata": {},
   "source": [
    "Convert numpy array to tensors - since we will be training our model using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "19aa6a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4e3df04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0985, -1.2851,  1.4055],\n",
      "        [ 0.4298,  0.8026,  0.2298]], requires_grad=True)\n",
      "tensor([-0.1701, -1.0593], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Initialize weight and bias with random numbers\n",
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b0d66a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple linear regression model\n",
    "def model(x):\n",
    "    return inputs @ w.t() + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889f0656",
   "metadata": {},
   "source": [
    "where `@` represnt matrix multiplication in PyTorch and `.t` return the transpose of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1c27d0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-18.6428,  93.9705],\n",
      "        [-14.3408, 123.3872],\n",
      "        [-82.2823, 157.2096],\n",
      "        [  6.6233,  85.7918],\n",
      "        [-18.3558, 121.7323]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e39f925",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7cf3c6",
   "metadata": {},
   "source": [
    "We evaluate our model performance by computing the mean squared error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "829b8b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -74.6428,   23.9705],\n",
       "        [ -95.3408,   22.3872],\n",
       "        [-201.2823,   24.2096],\n",
       "        [ -15.3767,   48.7918],\n",
       "        [-121.3558,    2.7323]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds - targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e0ce9f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return (torch.sum(diff ** 2)) / diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a63e4ad9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7418.9624, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compute loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c145efde",
   "metadata": {},
   "source": [
    "This means that on average each element in our predictions differs from the actual target by the square root of the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ecd1fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fe1308",
   "metadata": {},
   "source": [
    "Each element in the `w.grad` represent the loss with respect to the corresponding weight in `w`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d83be7",
   "metadata": {},
   "source": [
    "Since the derivate of the loss w.r.t. a particular weight indicate the rate of change of the loss as the weight is slightly changed, we can use this concept to reduce our loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da36fc",
   "metadata": {},
   "source": [
    "We can subtract from each weight element a small quantity proportional to the derivative of the loss w.r.t. that element to reduce the loss slightly. If the gradient is positive, then the weight decreases. However, if the gradient is negative, then the weight decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5eadb6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0985, -1.2851,  1.4055],\n",
      "        [ 0.4298,  0.8026,  0.2298]], requires_grad=True)\n",
      "tensor([[ -8315.6934, -10534.8477,  -6009.9331],\n",
      "        [  2211.7212,   1836.1052,   1172.8446]])\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "930217c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61373783",
   "metadata": {},
   "source": [
    "We multiply the gradients with a very small number (10^-5 in this case) to ensure that we do not modify the weights by a very large amount. \n",
    "\n",
    "Computing derivatives is an expensive operation. We use torch.no_grad to indicate to PyTorch that we shouldn't track, calculate, or modify gradients while updating the weights and biases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f429627f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: tensor(7418.9624, grad_fn=<DivBackward0>)\n",
      "Updated loss: tensor(5361.0703, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Let's verify that the loss is actually lower\n",
    "print(\"Initial loss:\", loss)\n",
    "\n",
    "pred = model(inputs)\n",
    "\n",
    "loss = mse(pred, targets)\n",
    "print(\"Updated loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd92f1",
   "metadata": {},
   "source": [
    "We reset the gradients to zero by calling the .zero_() method. This is because PyTorch accumulates gradients and we need to avoid the existing gradients being added to the new gradients.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2f718020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391df451",
   "metadata": {},
   "source": [
    "## Train the model using gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee32f333",
   "metadata": {},
   "source": [
    "As seen above, we reduce the loss and improve our model using the gradients descent optimization algorithm. Thus, we can train the model using the following steps:\n",
    "\n",
    "1. Generate Predictions\n",
    "2. Calculate the loss\n",
    "3. Compute gradients with respect to the weights and biases\n",
    "4. Adjust the weights by subtracting a small quantity proportional to the gradient\n",
    "5. Reset the gradients to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7bb7c81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -2.9287,  90.6212],\n",
      "        [  6.3445, 119.0079],\n",
      "        [-57.4442, 152.1445],\n",
      "        [ 21.8600,  82.3122],\n",
      "        [  1.7035, 117.6223]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1b385336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5361.0703, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss \n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5ded49ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6689.9653, -8778.3828, -4928.3169],\n",
      "        [ 1867.2826,  1469.5680,   945.9412]])\n",
      "tensor([-82.2930,  20.3416])\n"
     ]
    }
   ],
   "source": [
    "# Compute the gradients \n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3f11c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust weights and reset gradients\n",
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b2ecb5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2486, -1.0920,  1.5149],\n",
      "        [ 0.3890,  0.7696,  0.2086]], requires_grad=True)\n",
      "tensor([-0.1683, -1.0598], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# New weights and biases\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5739a069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3970.1011, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31ee8a2",
   "metadata": {},
   "source": [
    "## Train for multiple epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e66cac",
   "metadata": {},
   "source": [
    "To reduce the loss further, we can repeat the process of adjusting the weights an biases using the gradient multiple times. Each iteration is an called epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "eb49d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 100 epochs\n",
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d3cf2885",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(374.7664, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a250291b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 63.2298,  73.1528],\n",
       "        [ 95.7874,  97.7997],\n",
       "        [ 78.0563, 134.9118],\n",
       "        [ 57.4500,  54.0936],\n",
       "        [104.2895, 103.9684]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "09be07ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Targets\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e8b3c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for an extra 100 epochs\n",
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f9c67bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(154.7007, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a380d9e",
   "metadata": {},
   "source": [
    "## Linear Regression using Pytorch Built-ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8b9cdec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "410774af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70], \n",
    "                   [74, 66, 43],\n",
    "                   [91, 87, 65], \n",
    "                   [88, 134, 59],\n",
    "                   [101, 44, 37],\n",
    "                   [68, 96, 71],\n",
    "                   [73, 66, 44],\n",
    "                   [92, 87, 64],\n",
    "                   [87, 135, 57],\n",
    "                   [103, 43, 36],\n",
    "                   [68, 97, 70]],\n",
    "                   dtype='float32')\n",
    "                   \n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119], \n",
    "                    [57, 69], \n",
    "                    [80, 102],\n",
    "                    [118, 132],\n",
    "                    [21, 38],\n",
    "                    [104, 118],\n",
    "                    [57, 69],\n",
    "                    [82, 100],\n",
    "                    [118, 134],\n",
    "                    [20, 38],\n",
    "                    [102, 120]], dtype='float32')\n",
    "\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b710daf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 73.,  67.,  43.],\n",
       "        [ 91.,  88.,  64.],\n",
       "        [ 87., 134.,  58.],\n",
       "        [102.,  43.,  37.],\n",
       "        [ 69.,  96.,  70.],\n",
       "        [ 74.,  66.,  43.],\n",
       "        [ 91.,  87.,  65.],\n",
       "        [ 88., 134.,  59.],\n",
       "        [101.,  44.,  37.],\n",
       "        [ 68.,  96.,  71.],\n",
       "        [ 73.,  66.,  44.],\n",
       "        [ 92.,  87.,  64.],\n",
       "        [ 87., 135.,  57.],\n",
       "        [103.,  43.,  36.],\n",
       "        [ 68.,  97.,  70.]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb539b07",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c4999e",
   "metadata": {},
   "source": [
    "We'll create a TensorDataset, which allows to access rows from `inputs` and `targets` as tuples, and provides a standard API for working with many different types of datasets in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3bf3385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "7ada7fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define dataset\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7368d7a8",
   "metadata": {},
   "source": [
    "We'll also create a DataLoader, which can split the data into batches of a predefined size while training. It also provides other utilities like shuffling and random sampling of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "33ad6562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ce6c6576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "503966eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 88., 134.,  59.],\n",
      "        [ 87., 135.,  57.],\n",
      "        [ 73.,  66.,  44.],\n",
      "        [ 68.,  97.,  70.],\n",
      "        [103.,  43.,  36.]])\n",
      "tensor([[118., 132.],\n",
      "        [118., 134.],\n",
      "        [ 57.,  69.],\n",
      "        [102., 120.],\n",
      "        [ 20.,  38.]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96813f64",
   "metadata": {},
   "source": [
    "In each iteration, the data loader returns one batch of data with the given batch size. If `shuffle` is set to `True`, it shuffles the training data before creating batches. Shuffling helps randomize the input to the optimization algorithm, leading to a faster reduction in the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f40199",
   "metadata": {},
   "source": [
    "## nn.Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0204c0e9",
   "metadata": {},
   "source": [
    "Instead of initializing the weights & biases manually, we can define the model using the nn.linear class from PyTorch, which does it automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "22d9ab31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0212, -0.5354,  0.2916],\n",
      "        [-0.4104, -0.3464, -0.5111]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1150, -0.0735], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = nn.Linear(3, 2)\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4a0d193d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0212, -0.5354,  0.2916],\n",
       "         [-0.4104, -0.3464, -0.5111]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1150, -0.0735], requires_grad=True)]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "eb0e9c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -21.6755,  -75.2224],\n",
       "        [ -26.4155, -100.6177],\n",
       "        [ -52.8789, -111.8453],\n",
       "        [  -9.9608,  -75.7447],\n",
       "        [ -29.4154,  -97.4256],\n",
       "        [ -21.1189,  -75.2864],\n",
       "        [ -25.5886, -100.7823],\n",
       "        [ -52.5662, -112.7668],\n",
       "        [ -10.5173,  -75.6807],\n",
       "        [ -29.1450,  -97.5262],\n",
       "        [ -20.8486,  -75.3870],\n",
       "        [ -25.8589, -100.6817],\n",
       "        [ -53.7059, -111.6807],\n",
       "        [ -10.2311,  -75.6441],\n",
       "        [ -29.9720,  -97.3616]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574323e6",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f50a6e",
   "metadata": {},
   "source": [
    "Instead of defining a loss function manually, we can use built-in loss function mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ea6e4114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nn.functional\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f2456119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2930e7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24678.2520, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the loss for the current predictions\n",
    "loss_fn(preds, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b7436f",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88c79b6",
   "metadata": {},
   "source": [
    "Instead of manually manipulating the model's weights & biases using gradients, we can use the optimizer `optim.SGD`, where SGD is short for \"stochastic gradient descent\". The term stochastic indicates that samples are selected in random batches instead of as a single group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c9e38de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "bb18f289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 91.,  87.,  65.],\n",
      "        [ 69.,  96.,  70.],\n",
      "        [ 88., 134.,  59.],\n",
      "        [ 92.,  87.,  64.],\n",
      "        [ 73.,  66.,  44.]]) tensor([[ 80., 102.],\n",
      "        [103., 119.],\n",
      "        [118., 132.],\n",
      "        [ 82., 100.],\n",
      "        [ 57.,  69.]])\n",
      "tensor([[ 74.,  66.,  43.],\n",
      "        [ 68.,  96.,  71.],\n",
      "        [101.,  44.,  37.],\n",
      "        [ 87., 135.,  57.],\n",
      "        [102.,  43.,  37.]]) tensor([[ 57.,  69.],\n",
      "        [104., 118.],\n",
      "        [ 21.,  38.],\n",
      "        [118., 134.],\n",
      "        [ 22.,  37.]])\n",
      "tensor([[103.,  43.,  36.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 73.,  67.,  43.],\n",
      "        [ 68.,  97.,  70.],\n",
      "        [ 87., 134.,  58.]]) tensor([[ 20.,  38.],\n",
      "        [ 81., 101.],\n",
      "        [ 56.,  70.],\n",
      "        [102., 120.],\n",
      "        [119., 133.]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl:\n",
    "    print(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "802c7457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    \n",
    "    # Repeact for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train with batches of data\n",
    "        for xb, yb in train_dl:\n",
    "            \n",
    "            # 1. Generate predictions\n",
    "            pred =  model(xb)\n",
    "            \n",
    "            # 2. Compute the loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            # 3. Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # 4. Update parameters using gradients\n",
    "            opt.step()\n",
    "            \n",
    "            # 5. Reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        # Print the progress at the end of every 10th epoch \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "2126040d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 30.9586\n",
      "Epoch [20/100], Loss: 19.2758\n",
      "Epoch [30/100], Loss: 19.4214\n",
      "Epoch [40/100], Loss: 11.1591\n",
      "Epoch [50/100], Loss: 20.2170\n",
      "Epoch [60/100], Loss: 17.7810\n",
      "Epoch [70/100], Loss: 16.1689\n",
      "Epoch [80/100], Loss: 16.4028\n",
      "Epoch [90/100], Loss: 14.0094\n",
      "Epoch [100/100], Loss: 9.7674\n"
     ]
    }
   ],
   "source": [
    "fit(100, model, loss_fn, opt, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "b81a963d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.1723,  70.9516],\n",
       "        [ 82.3367,  97.6165],\n",
       "        [117.2547, 139.1190],\n",
       "        [ 21.9237,  40.2652],\n",
       "        [101.7591, 111.8979],\n",
       "        [ 55.9636,  69.8275],\n",
       "        [ 82.2329,  97.1398],\n",
       "        [117.5789, 139.4152],\n",
       "        [ 23.1324,  41.3893],\n",
       "        [102.8641, 112.5452],\n",
       "        [ 57.0686,  70.4749],\n",
       "        [ 81.1280,  96.4924],\n",
       "        [117.3585, 139.5957],\n",
       "        [ 20.8188,  39.6179],\n",
       "        [102.9679, 113.0220]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "09549eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 57.,  69.],\n",
       "        [ 80., 102.],\n",
       "        [118., 132.],\n",
       "        [ 21.,  38.],\n",
       "        [104., 118.],\n",
       "        [ 57.,  69.],\n",
       "        [ 82., 100.],\n",
       "        [118., 134.],\n",
       "        [ 20.,  38.],\n",
       "        [102., 120.]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with targets\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf7af4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
